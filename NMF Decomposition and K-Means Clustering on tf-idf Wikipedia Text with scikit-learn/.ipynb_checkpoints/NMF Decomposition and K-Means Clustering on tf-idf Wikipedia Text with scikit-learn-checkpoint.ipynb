{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Decomposition and K-Means Clustering on tf-idf Wikipedia Text with scikit-learn\n",
    "\n",
    "## By Christopher Hauman\n",
    "<br>\n",
    "\n",
    "### This example of NMF Decomposition was adapted from DataCamp's [Unsupervised Learning in Python](https://www.datacamp.com/courses/unsupervised-learning-in-python) course. This is a sequel to my walkthrough of [NMF Decomposition on LCD Digits Data](https://nbviewer.jupyter.org/github/chrisman1015/Unsupervised-Learning/blob/master/NMF%20Decomposition%20on%20LCD%20Digits/NMF%20Decomposition%20on%20LCD%20Digits.ipynb). This will add some complexity to that example, so please check that out if you need an introduction or a refresher. \n",
    "\n",
    "### Note: This assumes you have basic knowledge of python data science basics. If you don't, or encounter something you're not familiar with, don't worry! You can get a crash course in my guide, [Cleaning MLB Statcast Data using pandas DataFrames and seaborn Visualization](https://nbviewer.jupyter.org/github/chrisman1015/Cleaning-Statcast-Data/blob/master/Cleaning%20Statcast%20Data/Cleaning%20Statcast%20Data.ipynb).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to NMF's ability to deconstruct images into it's component patterns, it can deconstruct text data into common themes or topics.\n",
    "<br>\n",
    "\n",
    "Let's import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "df = pd.read_csv('wikipedia-vectors.csv', index_col=0)\n",
    "articles = csr_matrix(df.transpose())\n",
    "titles = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv we're working with contains a tf-idf frequency array, where each row is a document and each columns is a word. Each entry in the array is the weighted-frequency the word in that row appears in that document. Let's quickly look at the first 2 values for the Skrillex row in articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.049502\n",
       "1    0.000000\n",
       "Name: Skrillex, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Skrillex'][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first word, aaron (the first name of a keyboad player who toured with Skrillex) appears in [krillex's wikipedia page](https://en.wikipedia.org/wiki/Skrillex), while the word abandon does not. You can look at the words in the vocabulary text file to see which correspond to the frequencies (aaron and abandon are the first two words in the file).\n",
    "<br>\n",
    "\n",
    "On to the NMF! This time we're going to add a normalization step in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# Create an NMF model: nmf\n",
    "nmf = NMF(n_components=20, random_state=10)\n",
    "\n",
    "# Create a Normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(nmf, normalizer)\n",
    "\n",
    "# Apply fit_transform to artists: norm_features\n",
    "norm_features = pipeline.fit_transform(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we added this normalization was because it will allow to compute the [cosine similarity] between points. This means we'll be able to look through our articles and see which have  common themes or topics. [This website](https://python-data-science.readthedocs.io/en/latest/normalisation.html) has a nice image of normalization which may help you understand the necessity of normalization for cosine similarty. We'll now compute cosine similarities to the actor Russel Crowe and see which the NMF algorithm consider most similar to him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russell Crowe           1.000000\n",
      "Denzel Washington       0.848427\n",
      "Dakota Fanning          0.779560\n",
      "Michael Fassbender      0.756301\n",
      "Jessica Biel            0.753638\n",
      "Anne Hathaway           0.753422\n",
      "Catherine Zeta-Jones    0.752894\n",
      "Mila Kunis              0.752350\n",
      "Jennifer Aniston        0.751033\n",
      "Angelina Jolie          0.742789\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "\n",
    "# Select row of 'Bruce Springsteen': artist\n",
    "article = df.loc['Russell Crowe']\n",
    "\n",
    "# Compute cosine similarities: similarities with dot\n",
    "similarities = df.dot(article)\n",
    "\n",
    "# Display 7 articles with highest cosine similarity\n",
    "print(similarities.nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazingly, all ten of the closest similarities are also actors! The NMF model was able to pick out patterns which actors wikipedia pages had in common and use that to find similar articles! You should be able to see why this is extremely useful, as many web sources use algorithms like this to give users recommendations for similar articles or videos!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
