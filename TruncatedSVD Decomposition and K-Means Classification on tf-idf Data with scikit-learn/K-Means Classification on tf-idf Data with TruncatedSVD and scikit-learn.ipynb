{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruncatedSVD Decomposition and K-Means Classification on tf-idf Data with scikit-learn\n",
    "\n",
    "## By Christopher Hauman\n",
    "<br>\n",
    "\n",
    "### This is a sequel to my guides on [K-Means Classification on the Iris Dataset](https://nbviewer.jupyter.org/github/chrisman1015/Unsupervised-Learning/blob/master/K-Means%20Classification%20on%20the%20Iris%20Dataset%20with%20scikit-learn/K-Means%20Classification%20on%20the%20Iris%20Dataset%20with%20scikit-learn.ipynb0) and [Principal Component Analysis on the Iris Dataset](https://nbviewer.jupyter.org/github/chrisman1015/Unsupervised-Learning/blob/master/PCA%20on%20the%20Iris%20Dataset%20with%20scikit-learn/Principal%20Component%20Analysis.ipynb).\n",
    "\n",
    "### Note: This assumes you have basic knowledge of python data science basics. If you don't, or encounter something you're not familiar with, don't worry! You can get a crash course in my guide, [Cleaning MLB Statcast Data using pandas DataFrames and seaborn Visualization](https://nbviewer.jupyter.org/github/chrisman1015/Cleaning-Statcast-Data/blob/master/Cleaning%20Statcast%20Data/Cleaning%20Statcast%20Data.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "To begin with, we're going to introduce the concept of tf-idf data. tf-idf stands for 'term frequency-inverse document frequency' and the data consists of weighted frequency values. To illustrate this, we'll explain the example we're working with.\n",
    "<br>\n",
    "\n",
    "The tf-idf data we're going to work with is the weighted frequency of words in a set of Wikipedia articles. We have 60 articles, 13,125 words, and the entries of the tf-idf array are the weighted frequency of that word's appearence in the article in comparison to the rest of the articles. For instance, if the word 'the' appears in the article \"Internet Explorer\" 200 times, it would likely still have a lower value in the tf-idf table than the word 'Thomas' (the original author of IE) because 'the' appears many time in every article, while 'Thomas' may only appear in that single article.\n",
    "<br>\n",
    "\n",
    "As you can imagine, tf-idf has a lot of zero entries. If you take a look at the wikipedia-vocabulary text file, you should see why this is the case. 'Thomas' probably only has a nonzero value for the Internet Explorer article. Because of this, we often store tf-idf data in a [CSR matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html). This is a type of sparse matrix (meaning there aren't many nonzero values in the matrix) which saves memory by only storing the value for non-zero entries. This saves a lot of memory, but unfortunately isn't compatible with PCA. Fortunately, there's another option which performs the same operation as PCA on CSR matrices, called TruncatedSVD.\n",
    "<br>\n",
    "\n",
    "We're also going to crank the modeling up a notch by pairing the dimensionality reduction of TruncatedSVD with K-means classification. We'll see how the model uses the tf-idf data to classify it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('wikipedia-vectors.csv', index_col=0)\n",
    "articles = csr_matrix(df.transpose())\n",
    "titles = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to in other guides, we'll create a pipeline which applies the TruncatedSVD algorithm to the data followed by K-means classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've made the model, let's fit it to the tf-idf data (stored in the articles CSR matrix) and make the classification prediction in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pipeline.fit_predict(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll store the classified labels and values in a DataFrame and print them to see how the model classified them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cluster 0\n",
      "\n",
      "    label           article\n",
      "10      0    Global warming\n",
      "12      0      Nigel Lawson\n",
      "13      0  Connie Hedegaard\n",
      "14      0    Climate change\n",
      "16      0           350.org\n",
      "\n",
      "\n",
      "Cluster 1\n",
      "\n",
      "    label               article\n",
      "20      1        Angelina Jolie\n",
      "21      1    Michael Fassbender\n",
      "22      1     Denzel Washington\n",
      "23      1  Catherine Zeta-Jones\n",
      "24      1          Jessica Biel\n",
      "25      1         Russell Crowe\n",
      "26      1            Mila Kunis\n",
      "27      1        Dakota Fanning\n",
      "28      1         Anne Hathaway\n",
      "29      1      Jennifer Aniston\n",
      "\n",
      "\n",
      "Cluster 2\n",
      "\n",
      "    label      article\n",
      "40      2  Tonsillitis\n",
      "41      2  Hepatitis B\n",
      "42      2  Doxycycline\n",
      "43      2     Leukemia\n",
      "44      2         Gout\n",
      "45      2  Hepatitis C\n",
      "46      2   Prednisone\n",
      "47      2        Fever\n",
      "48      2   Gabapentin\n",
      "49      2     Lymphoma\n",
      "\n",
      "\n",
      "Cluster 3\n",
      "\n",
      "    label                article\n",
      "50      3           Chad Kroeger\n",
      "51      3             Nate Ruess\n",
      "52      3             The Wanted\n",
      "53      3           Stevie Nicks\n",
      "54      3         Arctic Monkeys\n",
      "55      3          Black Sabbath\n",
      "56      3               Skrillex\n",
      "57      3  Red Hot Chili Peppers\n",
      "58      3                 Sepsis\n",
      "59      3            Adam Levine\n",
      "\n",
      "\n",
      "Cluster 4\n",
      "\n",
      "   label                      article\n",
      "0      4                     HTTP 404\n",
      "1      4               Alexa Internet\n",
      "2      4            Internet Explorer\n",
      "3      4                  HTTP cookie\n",
      "4      4                Google Search\n",
      "5      4                       Tumblr\n",
      "6      4  Hypertext Transfer Protocol\n",
      "7      4                Social search\n",
      "8      4                      Firefox\n",
      "9      4                     LinkedIn\n",
      "\n",
      "\n",
      "Cluster 5\n",
      "\n",
      "    label                            article\n",
      "30      5      France national football team\n",
      "31      5                  Cristiano Ronaldo\n",
      "32      5                       Arsenal F.C.\n",
      "33      5                     Radamel Falcao\n",
      "34      5                 Zlatan Ibrahimović\n",
      "35      5    Colombia national football team\n",
      "36      5  2014 FIFA World Cup qualification\n",
      "37      5                           Football\n",
      "38      5                             Neymar\n",
      "39      5                      Franck Ribéry\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame aligning labels and titles: df\n",
    "df = pd.DataFrame({'label': labels, 'article': titles})\n",
    "\n",
    "# print clusters\n",
    "for i in range(6):\n",
    "    print(\"\\n\\nCluster \" + str(i) + \"\\n\")\n",
    "    print(df[df['label'] == i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no instruction on what categories to make, the model was able to classify actors, musical artists, sports-related articles, and make other groupings easily and accurately.\n",
    "<br>\n",
    "\n",
    "Though we couldn't use PCA, we were able to perform the same operation on the CSR matrix with truncatedSVD. If you want to take the next step and learn how to build a recommendation engine in python on tf-idf data, check out my guide on [NMF Decomposition and K-Means Clustering on tf-idf Wikipedia Text with scikit-learn](https://nbviewer.jupyter.org/github/chrisman1015/Unsupervised-Learning/blob/master/NMF%20Decomposition%20and%20K-Means%20Clustering%20on%20tf-idf%20Wikipedia%20Text%20with%20scikit-learn/NMF%20Decomposition%20and%20K-Means%20Clustering%20on%20tf-idf%20Wikipedia%20Text%20with%20scikit-learn.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf data originated [here](https://blog.lateral.io/2015/06/the-unknown-perils-of-mining-wikipedia/) and the code is adapted from Datacamp's course on [Unsupervised Learning](https://www.datacamp.com/courses/unsupervised-learning-in-python)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
